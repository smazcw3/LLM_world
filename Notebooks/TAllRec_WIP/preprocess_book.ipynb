{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da857dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the current path of the execution\n",
    "import sys\n",
    "import os\n",
    "cwd = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.append(cwd)\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae8e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1b31b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b42b9c",
   "metadata": {},
   "source": [
    "### Downloading Book-Crossing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2065317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading BX-Book-Ratings.csv from https://raw.githubusercontent.com/rochitasundar/Collaborative-Filtering-Book-Recommendation-System/master/BX-Book-Ratings.csv\n",
      "Successfully saved to datasets/book_crossing/BX-Book-Ratings.csv\n",
      "Downloading BX-Books.csv from https://raw.githubusercontent.com/rochitasundar/Collaborative-Filtering-Book-Recommendation-System/master/BX-Books.csv\n",
      "Successfully saved to datasets/book_crossing/BX-Books.csv\n",
      "Downloading BX-Users.csv from https://raw.githubusercontent.com/rochitasundar/Collaborative-Filtering-Book-Recommendation-System/master/BX-Users.csv\n",
      "Successfully saved to datasets/book_crossing/BX-Users.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'datasets/book_crossing'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Function to convert GitHub URL to raw URL\n",
    "def get_raw_url(github_url):\n",
    "    return github_url.replace('github.com', 'raw.githubusercontent.com').replace('/blob/', '/')\n",
    "\n",
    "# GitHub URLs for the dataset files\n",
    "github_urls = [\n",
    "    'https://github.com/rochitasundar/Collaborative-Filtering-Book-Recommendation-System/blob/master/BX-Book-Ratings.csv',\n",
    "    'https://github.com/rochitasundar/Collaborative-Filtering-Book-Recommendation-System/blob/master/BX-Books.csv',\n",
    "    'https://github.com/rochitasundar/Collaborative-Filtering-Book-Recommendation-System/blob/master/BX-Users.csv'\n",
    "]\n",
    "\n",
    "# Download all files\n",
    "for url in github_urls:\n",
    "    raw_url = get_raw_url(url)\n",
    "    filename = url.split('/')[-1]\n",
    "    local_path = os.path.join(data_dir, filename)\n",
    "    \n",
    "    print(f\"Downloading {filename} from {raw_url}\")\n",
    "    response = requests.get(raw_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(local_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Successfully saved to {local_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {filename}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d98e16",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b9dcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading downloaded files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1d/mmxhlk0x4tdf4cx6sd6q_ydr0000gn/T/ipykernel_61791/4016619096.py:12: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  books = pd.read_csv(os.path.join(data_dir, \"BX-Books.csv\"), sep=';', encoding=\"latin-1\", error_bad_lines=False)\n",
      "b'Skipping line 6452: expected 8 fields, saw 9\\nSkipping line 43667: expected 8 fields, saw 10\\nSkipping line 51751: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 92038: expected 8 fields, saw 9\\nSkipping line 104319: expected 8 fields, saw 9\\nSkipping line 121768: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 144058: expected 8 fields, saw 9\\nSkipping line 150789: expected 8 fields, saw 9\\nSkipping line 157128: expected 8 fields, saw 9\\nSkipping line 180189: expected 8 fields, saw 9\\nSkipping line 185738: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 209388: expected 8 fields, saw 9\\nSkipping line 220626: expected 8 fields, saw 9\\nSkipping line 227933: expected 8 fields, saw 11\\nSkipping line 228957: expected 8 fields, saw 10\\nSkipping line 245933: expected 8 fields, saw 9\\nSkipping line 251296: expected 8 fields, saw 9\\nSkipping line 259941: expected 8 fields, saw 9\\nSkipping line 261529: expected 8 fields, saw 9\\n'\n",
      "/var/folders/1d/mmxhlk0x4tdf4cx6sd6q_ydr0000gn/T/ipykernel_61791/4016619096.py:12: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(os.path.join(data_dir, \"BX-Books.csv\"), sep=';', encoding=\"latin-1\", error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating shape: (1031136, 10)\n",
      "Users shape: (278858, 3)\n",
      "Books shape: (271360, 8)\n",
      "Created book_item_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "# Now read the files using your original format\n",
    "print(\"\\nReading downloaded files...\")\n",
    "\n",
    "# Read the files using the format you specified\n",
    "try:\n",
    "    rating = pd.read_csv(os.path.join(data_dir, \"BX-Book-Ratings.csv\"), sep=';', encoding=\"latin-1\")\n",
    "    users = pd.read_csv(os.path.join(data_dir, \"BX-Users.csv\"), sep=';', encoding=\"latin-1\")\n",
    "    \n",
    "    # Note: error_bad_lines is deprecated in newer pandas versions\n",
    "    # Use on_bad_lines='skip' instead for newer pandas versions\n",
    "    try:\n",
    "        books = pd.read_csv(os.path.join(data_dir, \"BX-Books.csv\"), sep=';', encoding=\"latin-1\", error_bad_lines=False)\n",
    "    except TypeError:\n",
    "        books = pd.read_csv(os.path.join(data_dir, \"BX-Books.csv\"), sep=';', encoding=\"latin-1\", on_bad_lines='skip')\n",
    "    \n",
    "    # Merge rating with books on ISBN\n",
    "    rating = pd.merge(rating, books, on='ISBN', how='inner')\n",
    "    \n",
    "    # Save books dataframe to a new CSV file\n",
    "    books.to_csv(os.path.join(data_dir, 'book_item_mapping.csv'), index=True)\n",
    "    \n",
    "    # Print information about the dataframes\n",
    "    print(f\"Rating shape: {rating.shape}\")\n",
    "    print(f\"Users shape: {users.shape}\")\n",
    "    print(f\"Books shape: {books.shape}\")\n",
    "    print(f\"Created book_item_mapping.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b77fdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6543</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8680</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>9</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating            Book-Title Book-Author  \\\n",
       "0   276725  034545104X            0  Flesh Tones: A Novel  M. J. Rose   \n",
       "1     2313  034545104X            5  Flesh Tones: A Novel  M. J. Rose   \n",
       "2     6543  034545104X            0  Flesh Tones: A Novel  M. J. Rose   \n",
       "3     8680  034545104X            5  Flesh Tones: A Novel  M. J. Rose   \n",
       "4    10314  034545104X            9  Flesh Tones: A Novel  M. J. Rose   \n",
       "\n",
       "  Year-Of-Publication         Publisher  \\\n",
       "0                2002  Ballantine Books   \n",
       "1                2002  Ballantine Books   \n",
       "2                2002  Ballantine Books   \n",
       "3                2002  Ballantine Books   \n",
       "4                2002  Ballantine Books   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/034545104X.0...   \n",
       "1  http://images.amazon.com/images/P/034545104X.0...   \n",
       "2  http://images.amazon.com/images/P/034545104X.0...   \n",
       "3  http://images.amazon.com/images/P/034545104X.0...   \n",
       "4  http://images.amazon.com/images/P/034545104X.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/034545104X.0...   \n",
       "1  http://images.amazon.com/images/P/034545104X.0...   \n",
       "2  http://images.amazon.com/images/P/034545104X.0...   \n",
       "3  http://images.amazon.com/images/P/034545104X.0...   \n",
       "4  http://images.amazon.com/images/P/034545104X.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/034545104X.0...  \n",
       "1  http://images.amazon.com/images/P/034545104X.0...  \n",
       "2  http://images.amazon.com/images/P/034545104X.0...  \n",
       "3  http://images.amazon.com/images/P/034545104X.0...  \n",
       "4  http://images.amazon.com/images/P/034545104X.0...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0217794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "271360it [00:08, 32982.30it/s]\n",
      "1031136it [00:49, 20883.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of books rated by a user: 11144\n",
      "Number of users with more than 3 ratings: 24268\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "user_dict = {}\n",
    "item_id = {}\n",
    "mx = 0  # Initialize mx before using it\n",
    "\n",
    "# Create mapping from ISBN to index\n",
    "for index, row in tqdm(books.iterrows()):\n",
    "    item_id[row['ISBN']] = index\n",
    "\n",
    "# Process ratings\n",
    "for index, row in tqdm(rating.iterrows()):\n",
    "    userid = row['User-ID']\n",
    "    \n",
    "    # Check if ISBN exists in item_id to avoid KeyError\n",
    "    if row['ISBN'] not in item_id:\n",
    "        continue\n",
    "        \n",
    "    # More Pythonic way to check if key exists\n",
    "    if userid not in user_dict:\n",
    "        user_dict[userid] = {\n",
    "            'ISBN': [],\n",
    "            'Book-Rating': [],\n",
    "            'Book-Title': [],\n",
    "            'Book-Author': [],\n",
    "            'Year-Of-Publication': [],\n",
    "        }\n",
    "    \n",
    "    # Add data to user dictionary\n",
    "    user_dict[userid]['ISBN'].append(item_id[row['ISBN']])\n",
    "    user_dict[userid]['Book-Rating'].append(float(row['Book-Rating']))\n",
    "    user_dict[userid]['Book-Title'].append(row['Book-Title'])\n",
    "    user_dict[userid]['Book-Author'].append(row['Book-Author'])\n",
    "    user_dict[userid]['Year-Of-Publication'].append(row['Year-Of-Publication'])\n",
    "\n",
    "# Filter users with more than 3 ratings\n",
    "new_user_dict = {}\n",
    "for key in user_dict.keys():\n",
    "    # Update max length\n",
    "    mx = max(mx, len(user_dict[key]['ISBN']))\n",
    "    \n",
    "    # Filter users with more than 3 ratings\n",
    "    if len(user_dict[key]['ISBN']) > 3:  # Changed <= to > to match your intent\n",
    "        new_user_dict[key] = user_dict[key]\n",
    "\n",
    "print(f\"Maximum number of books rated by a user: {mx}\")\n",
    "print(f\"Number of users with more than 3 ratings: {len(new_user_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "decf42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split users into train/valid/test sets\n",
    "user_list = list(new_user_dict.keys())\n",
    "random.seed(42)  # Set seed once at the beginning\n",
    "random.shuffle(user_list)\n",
    "\n",
    "train_user = user_list[:int(len(user_list) * 0.8)]\n",
    "valid_user = user_list[int(len(user_list) * 0.8):int(len(user_list) * 0.9)]\n",
    "test_user = user_list[int(len(user_list) * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e8e83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv(user_list, output_csv, output_json, user_dict):\n",
    "    nrows = []\n",
    "    for user in user_list:\n",
    "        item_id = user_dict[user]['ISBN'].copy()  # Create copies to avoid modifying original data\n",
    "        rating = [int(_ > 5) for _ in user_dict[user]['Book-Rating']]\n",
    "        \n",
    "        # Use a different seed for each user to ensure diversity\n",
    "        random_seed = hash(user) % 10000\n",
    "        random.seed(random_seed)\n",
    "        \n",
    "        # Shuffle both lists with the same seed\n",
    "        combined = list(zip(item_id, rating))\n",
    "        random.shuffle(combined)\n",
    "        item_id, rating = zip(*combined)  # Unzip\n",
    "        \n",
    "        # Convert back to lists\n",
    "        item_id = list(item_id)\n",
    "        rating = list(rating)\n",
    "        \n",
    "        nrows.append([user, item_id[:-1][:10], rating[:-1][:10], item_id[-1], rating[-1]])\n",
    "    \n",
    "    with open(output_csv, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['user', 'history_item_id', 'history_rating', 'item_id', 'rating'])\n",
    "        writer.writerows(nrows)\n",
    "    \n",
    "    Prompt_json = []\n",
    "    for user in user_list:\n",
    "        # Create copies of all lists\n",
    "        item_id = user_dict[user]['ISBN'].copy()\n",
    "        rating = [int(_ > 5) for _ in user_dict[user]['Book-Rating']]\n",
    "        book_title = user_dict[user]['Book-Title'].copy()\n",
    "        book_author = user_dict[user]['Book-Author'].copy()\n",
    "        \n",
    "        # Use a consistent seed for this user\n",
    "        random_seed = hash(user) % 10000\n",
    "        random.seed(random_seed)\n",
    "        \n",
    "        # Shuffle all lists together to maintain correspondence\n",
    "        combined = list(zip(item_id, rating, book_title, book_author))\n",
    "        random.shuffle(combined)\n",
    "        item_id, rating, book_title, book_author = zip(*combined)\n",
    "        \n",
    "        # Convert back to lists\n",
    "        item_id = list(item_id)\n",
    "        rating = list(rating)\n",
    "        book_title = list(book_title)\n",
    "        book_author = list(book_author)\n",
    "        \n",
    "        preference = []\n",
    "        unpreference = []\n",
    "        for i in range(min(len(item_id) - 1, 10)):\n",
    "            if rating[i] == 1:\n",
    "                preference.append(f'\"{book_title[i]}\" written by {book_author[i]}')\n",
    "            else:\n",
    "                unpreference.append(f'\"{book_title[i]}\" written by {book_author[i]}')\n",
    "        \n",
    "        preference_str = \", \".join(preference)\n",
    "        unpreference_str = \", \".join(unpreference)\n",
    "        \n",
    "        target_preference_str = \"Yes.\" if rating[-1] == 1 else \"No.\"\n",
    "        target_book_str = f'\"{book_title[-1]}\" written by {book_author[-1]}'\n",
    "        \n",
    "        Prompt_json.append({\n",
    "            \"instruction\": \"Given the user's preference and unpreference, identify whether the user will like the target book by answering \\\"Yes.\\\" or \\\"No.\\\".\",\n",
    "            \"input\": f\"User Preference: {preference_str}\\nUser Unpreference: {unpreference_str}\\nWhether the user will like the target book {target_book_str}?\",\n",
    "            \"output\": target_preference_str,\n",
    "        })\n",
    "    \n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(Prompt_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88725241",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_csv(train_user, os.path.join(data_dir, 'train.csv'), os.path.join(data_dir, 'train.json'), new_user_dict)\n",
    "generate_csv(valid_user, os.path.join(data_dir, 'valid.csv'), os.path.join(data_dir, 'valid.json'), new_user_dict)\n",
    "generate_csv(test_user, os.path.join(data_dir, 'test.csv'), os.path.join(data_dir, 'test.json'), new_user_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd1cf1c",
   "metadata": {},
   "source": [
    "### Reading a sample (Task Instruction + Task Input, Task Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a05bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the user's preference and unpreference, identify whether the user will like the target book by answering \"Yes.\" or \"No.\".\n",
      "User Preference: \"The End of Enemies (Briggs Tanner Novels)\" written by Grant Blackwood, \"Q Is for Quarry\" written by Sue Grafton\n",
      "User Unpreference: \"ICEFIRE\" written by Judith Reeves-Stevens\n",
      "Whether the user will like the target book \"Specter of the Past: Star Wars (Star Wars (Bantam Books (Firm) : Unnumbered).)\" written by Timothy Zahn?\n",
      "Yes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_dir, \"train.json\"), 'r') as lst:\n",
    "    b = json.load(lst)\n",
    "    \n",
    "for line in b:\n",
    "    print(line[\"instruction\"])\n",
    "    print(line[\"input\"])\n",
    "    print(line[\"output\"])\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0749c6c",
   "metadata": {},
   "source": [
    "### Cleaning up the data within datasets once done with work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa33333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.common import cleanup\n",
    "# data_dir = \"datasets\"\n",
    "# cleanup(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860f482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
