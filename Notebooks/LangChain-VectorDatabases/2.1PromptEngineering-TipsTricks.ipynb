{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b869265",
   "metadata": {},
   "source": [
    "Reference -- https://colab.research.google.com/drive/1JZRY4CO7A8t5LP_72jkqbuGliVcgsPQz?usp=sharing#scrollTo=1_R56C3dgK49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd05af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langchain==0.0.208 openai==0.27.8 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9ecff3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dda31c",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c237d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: interstellar travel\n",
      "Year: 3030\n",
      "AI-generated song title: \"Galactic Odyssey: Journey to the Stars\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "#Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0)\n",
    "\n",
    "template = \"\"\"\n",
    "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
    "What's a cool song title for a song about {theme} in the year {year}?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"theme\", \"year\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "#Create the LLMChain for the prompt\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "#Input data for the prompt\n",
    "input_data = {\"theme\": \"interstellar travel\", \"year\": \"3030\"}\n",
    "\n",
    "#Run the LLMChain to get the AI-generated song title\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(\"Theme: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(f\"AI-generated song title: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f36a7",
   "metadata": {},
   "source": [
    "## Few Shot Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f6b95d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: purple\n",
      "Emotion: royalty or luxury\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
    "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
    "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
    "]\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Color: {color}\n",
    "Emotion: {emotion}\\n\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"color\", \"emotion\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Here are some examples of colors and the demotions associated with them:\\n\\n\",\n",
    "    suffix=\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")\n",
    "\n",
    "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
    "\n",
    "#Create the LLMChain for the prompt\n",
    "chain = LLMChain(llm=llm, prompt=PromptTemplate(template=formatted_prompt, input_variables=[]))\n",
    "\n",
    "#Run the LLMChain to get the AI-generated emotion assoicated with the input color\n",
    "response = chain.run({})\n",
    "\n",
    "print(\"Color: purple\")\n",
    "print(f\"Emotion: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7de3507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me something about dogs.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Tell me something about {topic}.\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "prompt.format(topic=\"dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f5ea955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Albert Einstein\n",
      "Fact: Albert Einstein's theory of general relativity is a fundamental theory in physics that describes the force of gravity as a curvature of spacetime caused by the presence of mass and energy. According to this theory, massive objects like planets and stars warp the fabric of spacetime, causing other objects to move along curved paths. General relativity also predicts the existence of phenomena such as gravitational time dilation and gravitational waves. This theory has been confirmed through numerous experimental observations and is a cornerstone of modern physics.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of general relativity.\n",
    "Answer: \n",
    "\"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3891811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Albert Einstein\n",
      "Fact: Albert Einstein was offered the presidency of Israel in 1952, but he declined the offer, stating that he lacked the necessary experience and was too old for the position.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Tell me something interesting about {scientist}.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ce80ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres: jazz pop rock\n",
      "Fact: Jazz, pop, and rock are all popular genres of music that have had a significant impact on the music industry and have influenced countless artists and musicians. Each genre has its own unique characteristics and appeal to different audiences.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "template_question = \"\"\"What are some musical genres?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Tell me something about {genre1}, {genre2}, and {genre3} without giving any specific details.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"genre1\", \"genre2\", \"genre3\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Assign three hardcoded genres\n",
    "genre1, genre2, genre3 = \"jazz\", \"pop\", \"rock\"\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"genre1\": genre1, \"genre2\": genre2, \"genre3\": genre3}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Genres:\", genre1, genre2, genre3)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f8825c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What are some tips for improving communication skills?\n",
      "AI Response: Practice active listening, be mindful of your body language, and ask open-ended questions to encourage meaningful conversations.\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"Finding balance in life and learning to enjoy the small moments.\"\n",
    "    }, {\n",
    "        \"query\": \"How can I become more productive?\",\n",
    "        \"answer\": \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "life coach. The assistant provides insightful and practical advice to the users' questions. Here are some\n",
    "examples:\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the few-shot prompt template\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "# Define the user query\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "\n",
    "# Run the LLMChain for the user query\n",
    "response = chain.run({\"query\": user_query})\n",
    "\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"AI Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ed9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
