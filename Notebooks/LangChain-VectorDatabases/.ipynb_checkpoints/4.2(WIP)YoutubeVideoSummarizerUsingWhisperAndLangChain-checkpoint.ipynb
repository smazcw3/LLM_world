{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ac648d",
   "metadata": {},
   "source": [
    "Reference -- https://colab.research.google.com/drive/1MvFJpyMStxDlq31wRshWB07nykxoME3-?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1bdc8",
   "metadata": {},
   "source": [
    "## Create a YouTube Video Summarizer Using Whisper and LangChain \n",
    "We previously explored the powerful feature of LangChain called chains, which allow for the creation of an end-to-end pipeline for using language models. We learned how chains combine multiple components such as models, prompts, memory, parsing output, and debugging to provide a user-friendly interface. We also discussed the process of designing custom pipelines by inheriting the Chain class and explored the LLMChain as a simple example. This lesson served as a foundation for future lessons, where we will apply these concepts to a hands-on project of summarizing a YouTube video.\n",
    "\n",
    "During this lesson, we delved into the challenge of summarizing YouTube videos efficiently in the context of the digital age. It will introduce two cutting-edge tools, Whisper and LangChain, that can help tackle this issue. We will discuss the strategies of \"stuff,\" \"map-reduce,\" and \"refine\" for handling large amounts of text and extracting valuable information. It is possible to effectively extract key takeaways from videos by leveraging Whisper to transcribe YouTube audio files and utilizing LangChain's summarization techniques, including stuff, refine, and map_reduce. We also highlighted the customizability of LangChain, allowing personalized prompts, multilingual summaries, and storage of URLs in a Deep Lake vector store. By implementing these advanced tools, you can save time, enhance knowledge retention, and improve your understanding of various topics. Enjoy the tailored experience of data storage and summarization with LangChain and Whisper.\n",
    "\n",
    "The following diagram explains what we are going to do in this project.\n",
    "\n",
    "<img src=\"../../images/YoutubeVideo.png\" width=500 height=100 />\n",
    "\n",
    "First, we download the youtube video we are interested in and transcribe it using Whisper. Then, we’ll proceed by creating summaries using two different approaches:\n",
    "\n",
    "1. First we use an existing summarization chain to generate the final summary, which automatically manages embeddings and prompts.\n",
    "\n",
    "2. Then, we use another approach more step-by-step to generate a final summary formatted in bullet points, consisting in splitting the transcription into chunks, computing their embeddings, and preparing ad-hoc prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd05af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.0.208 deeplake openai==0.27.8 tiktoken scikit-learn deeplake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9330f13",
   "metadata": {},
   "source": [
    "Additionally, install also the `yt_dlp` and `openai-whisper` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f13822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q yt_dlp\n",
    "# !pip install -q git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92308e2",
   "metadata": {},
   "source": [
    "Then, we must install the ffmpeg application, which is one of the requirements for the yt_dlp package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdcc6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MacOS (requires https://brew.sh/)\n",
    "#brew install ffmpeg\n",
    "\n",
    "# Ubuntu\n",
    "#sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ecff3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f691aab",
   "metadata": {},
   "source": [
    "For this experiment, we have selected a video featuring Yann LeCun, a distinguished computer scientist and AI researcher. In this engaging discussion, LeCun delves into the challenges posed by large language models.\n",
    "\n",
    "The `download_mp4_from_youtube()` function will download the best quality mp4 video file from any YouTube link and save it to the specified path and filename. We just need to copy/paste the selected video’s URL and pass it to mentioned function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008332de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] YouTube said: ERROR - Precondition check failed.\n",
      "WARNING: [youtube] HTTP Error 400: Bad Request. Retrying (1/3)...\n",
      "WARNING: [youtube] YouTube said: ERROR - Precondition check failed.\n",
      "WARNING: [youtube] HTTP Error 400: Bad Request. Retrying (2/3)...\n",
      "WARNING: [youtube] YouTube said: ERROR - Precondition check failed.\n",
      "WARNING: [youtube] HTTP Error 400: Bad Request. Retrying (3/3)...\n",
      "WARNING: [youtube] YouTube said: ERROR - Precondition check failed.\n",
      "WARNING: [youtube] Unable to download API page: HTTP Error 400: Bad Request (caused by <HTTPError 400: Bad Request>); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def download_mp4_from_youtube(url):\n",
    "    # Set the options for the download\n",
    "    filename = 'lecuninterview.mp4'\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]',\n",
    "        'outtmpl': filename,\n",
    "        'quiet': True,\n",
    "    }\n",
    "\n",
    "    # Download the video file\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        result = ydl.extract_info(url, download=True)\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=mBjPyte2ZZo\"\n",
    "download_mp4_from_youtube(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfea4bd",
   "metadata": {},
   "source": [
    "### Now it’s time for Whisper!\n",
    "\n",
    "Whisper is a cutting-edge, automatic speech recognition system developed by OpenAI. Boasting state-of-the-art capabilities, Whisper has been trained on an impressive 680,000 hours of multilingual and multitasking supervised data sourced from the web.  This vast and varied dataset enhances the system's robustness, enabling it to handle accents, background noise, and technical language easily. OpenAI has released the models and codes to provide a solid foundation for creating valuable applications harnessing the power of speech recognition.\n",
    "\n",
    "The whisper package that we installed earlier provides the `.load_model()` method to download the model and transcribe a video file. Multiple different models are available: `tiny`, `base`, `small`, `medium`, and `large`. Each one of them has tradeoffs between accuracy and speed. We will use the `base` model for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb545697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smaz-home/anaconda3/lib/python3.8/site-packages/numba/core/types/__init__.py:108: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.\n",
      "  long_ = _make_signed(np.long)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1d/mmxhlk0x4tdf4cx6sd6q_ydr0000gn/T/ipykernel_57495/3807503465.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lecuninterview.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/whisper/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_mel_spectrogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_or_trim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdecoding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecodingResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetect_language\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelDimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranscribe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/whisper/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdecoding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdecode_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdecoding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect_language\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetect_language_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranscribe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtranscribe_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdecoding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecodingResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtiming\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_word_timestamps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLANGUAGES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTO_LANGUAGE_CODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m from .utils import (\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/whisper/timing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numba/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_runtests\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mruntests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Re-export typeof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numba/core/types/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mintc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_signed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# C-compat int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0muintc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_unsigned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muintc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# C-compat uint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mlong_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_signed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0mulong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_unsigned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mlonglong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_signed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlonglong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    321\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'long'"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"lecuninterview.mp4\")\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6228e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
